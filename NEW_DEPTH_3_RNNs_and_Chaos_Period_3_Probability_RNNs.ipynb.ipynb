{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Depth_3_RNNs_and_Chaos_Period_3_Probability_RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Characteristics of Network\n",
        "\n",
        "# Network Characteristics:\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "#|         Layer_1         |         Layer_2         ||    Chaos Percentage     |\n",
        "#|   w       b       σ()   |   w       b       σ()   ||                         |\n",
        "#|   1      He      ReLU   |   He     He        1    ||          ~13.77 %       |\n",
        "#|   He     He      ReLU   |   He     He      ReLU   ||           ~4.51 %       |\n",
        "#|   He      U      ReLU   |   He     U       ReLU   ||           ~7.49 %       |\n",
        "#|N(0,1/k) TR(-1,1) ReLU   |N(0,1/k) TR(-1,1) ReLU   ||           ~4.4 %        |\n",
        "#|Glorot   Glorot   ReLU   |Glorot   Glorot   ReLU   ||           ~2.28 %       |\n",
        "#|-------------------------|-------------------------||-------------------------|"
      ],
      "metadata": {
        "id": "zwCc33NjoJgy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3e7NrKrBd30H"
      },
      "outputs": [],
      "source": [
        "# Import Packages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import figure\n",
        "from scipy.interpolate import make_interp_spline\n",
        "from scipy.stats import truncnorm\n",
        "import scipy.stats as stats\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats\n",
        "lower = 0\n",
        "upper = 1\n",
        "mu = 0.5\n",
        "sigma = 0.1\n",
        "N = 1\n",
        "\n",
        "samples = scipy.stats.truncnorm.rvs(\n",
        "          (lower-mu)/sigma,(upper-mu)/sigma,loc=mu,scale=sigma,size=N)\n",
        "\n",
        "n_inputs = 2\n",
        "n_neurons = 3\n",
        "weights = np.zeros((n_inputs,n_neurons))\n",
        "\n",
        "for i in range(len(weights)):\n",
        "  for j in range(len(weights[0])):\n",
        "    weights[i][j] = scipy.stats.truncnorm.rvs((lower-mu)/sigma,(upper-mu)/sigma,loc=mu,scale=sigma,size=N)[0]\n",
        "\n",
        "print(weights)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im-Zh_FneZVu",
        "outputId": "25575dab-a2c7-46ea-9c84-d56b39a0f065"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.52141357 0.45262783 0.45187444]\n",
            " [0.63644439 0.69526714 0.24157978]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense Layer 1\n",
        "class Layer_Dense_In:\n",
        "\n",
        "  # Layer initialization\n",
        "  def __init__(self,n_inputs,n_neurons,w,b):\n",
        "    '''\n",
        "    Weight Initialization\n",
        "    '''\n",
        "    if w == 'he':\n",
        "      # He Initialization\n",
        "      self.weights = np.random.randn(n_inputs, n_neurons) * np.sqrt(2/n_inputs)\n",
        "    elif w == '1':\n",
        "      # 1 Initialization\n",
        "      self.weights = np.ones((n_inputs, n_neurons))\n",
        "    elif w == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.weights = 1 * np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.weights = (1/n_neurons)* np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'uniform':\n",
        "      # Uniform Initialization\n",
        "      self.weights = np.random.uniform(size=(n_inputs,n_neurons))\n",
        "    elif w == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.weights = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(n_inputs, n_neurons)\n",
        "    '''\n",
        "    Bias Initialization\n",
        "    '''\n",
        "    if b == 'he':\n",
        "      # He Initialization\n",
        "      self.biases = np.random.randn(1,n_neurons)* np.sqrt(2/n_inputs)\n",
        "    elif b == '1':\n",
        "      # 1 Initialization\n",
        "      self.biases = np.zeros((1, n_neurons))\n",
        "    elif b == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.biases = 1 * np.random.randn(1,n_neurons)\n",
        "    elif b == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.biases = (1/n_neurons)* np.random.randn(n_inputs, n_neurons)\n",
        "    elif b == 'uniform':\n",
        "      # Uniform Distribution\n",
        "      self.biases = np.random.uniform(size=(1,n_neurons))\n",
        "    elif b == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.biases = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(1, n_neurons)\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "# Dense Layer 2\n",
        "class Layer_Dense_Mid:\n",
        "\n",
        "  # Layer initialization\n",
        "  def __init__(self,n_inputs,n_neurons,w,b):\n",
        "    '''\n",
        "    Weight Initialization\n",
        "    '''\n",
        "    if w == 'he':\n",
        "      # He Initialization\n",
        "      self.weights = np.random.randn(n_inputs, n_neurons) * np.sqrt(2/n_inputs)\n",
        "    elif w == '1':\n",
        "      # 1 Initialization\n",
        "      self.weights = np.ones((n_inputs, n_neurons))\n",
        "    elif w == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.weights = 1 * np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.weights = (1/n_neurons)* np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'uniform':\n",
        "      # Uniform Initialization\n",
        "      self.weights = np.random.uniform(size=(n_inputs,n_neurons))\n",
        "    elif w == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.weights = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(n_inputs, n_neurons)\n",
        "    '''\n",
        "    Bias Initialization\n",
        "    '''\n",
        "    if b == 'he':\n",
        "      # He Initialization\n",
        "      self.biases = np.random.randn(1,n_neurons)* np.sqrt(2/n_inputs)\n",
        "    elif b == '1':\n",
        "      # 1 Initialization\n",
        "      self.biases = np.zeros((1, n_neurons))\n",
        "    elif b == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.biases = 1 * np.random.randn(1,n_neurons)\n",
        "    elif b == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.biases = (1/n_neurons)* np.random.randn(1, n_neurons)\n",
        "    elif b == 'uniform':\n",
        "      # Uniform Distribution\n",
        "      self.biases = np.random.uniform(size=(1,n_neurons))\n",
        "    elif b == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.biases = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(1, n_neurons)\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "# Dense Layer 3\n",
        "class Layer_Dense_Out:\n",
        "  \n",
        "    # Layer initialization\n",
        "  def __init__(self,n_inputs,n_neurons,w,b,clip):\n",
        "\n",
        "    if clip == 'clip':\n",
        "      self.clipping_flag = True\n",
        "    else:\n",
        "      self.clipping_flag = False\n",
        "    '''\n",
        "    Weight Initialization\n",
        "    '''\n",
        "    if w == 'he':\n",
        "      # He Initialization\n",
        "      self.weights = np.random.randn(n_inputs, n_neurons) * np.sqrt(2/n_inputs)\n",
        "    elif w == '1':\n",
        "      # 1 Initialization\n",
        "      self.weights = np.ones((n_inputs, n_neurons))\n",
        "    elif w == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.weights = 1 * np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.weights = (1/n_neurons)* np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'uniform':\n",
        "      # Uniform Initialization\n",
        "      self.weights = np.random.uniform(size=(n_inputs,n_neurons))\n",
        "    elif w == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.weights = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(n_inputs, n_neurons)\n",
        "    '''\n",
        "    Bias Initialization\n",
        "    '''\n",
        "    if b == 'he':\n",
        "      # He Initialization\n",
        "      self.biases = np.random.randn(1,n_neurons)* np.sqrt(2/n_inputs)\n",
        "    elif b == '1':\n",
        "      # 1 Initialization\n",
        "      self.biases = np.zeros((1, n_neurons))\n",
        "    elif b == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.biases = 1 * np.random.randn(1,n_neurons)\n",
        "    elif b == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.biases = (1/n_neurons)* np.random.randn(1, n_neurons)\n",
        "    elif b == 'uniform':\n",
        "      # Uniform Distribution\n",
        "      self.biases = np.random.uniform(size=(1,n_neurons))\n",
        "    elif b == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.biases = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(1, n_neurons)\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Output clipping [0,1]\n",
        "    if self.clipping_flag == True:\n",
        "      if self.output > 1:\n",
        "        self.output = 1\n",
        "      if self.output < 0:\n",
        "        self.output = 0"
      ],
      "metadata": {
        "id": "JPuv3ulaePI1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU activation\n",
        "class Activation_ReLU:\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    # Calculate output values from inputs\n",
        "    self.output = np.maximum(0,inputs)\n",
        "\n",
        "# Tanh activation\n",
        "class Activation_Tanh:\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    # Calculate output values from inputs\n",
        "    self.output = np.tanh(inputs)\n",
        "\n",
        "# Data Flow at every composition\n",
        "def RNN_Pass(input):\n",
        "\n",
        "  layer_in.forward(input)\n",
        "  layer_act1.forward(layer_in.output)\n",
        "  layer_mid.forward(layer_act1.output)\n",
        "  layer_act2.forward(layer_mid.output)\n",
        "  layer_out.forward(layer_act2.output)\n",
        "  layer_act3.forward(layer_out.output)\n",
        "\n",
        "  return layer_act3.output"
      ],
      "metadata": {
        "id": "DdckGOkehIr1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Loop - Mapping of [0,1] -> [0,1]\n",
        "\n",
        "# Initialization parameters:\n",
        "# * Network Depth\n",
        "# * Image Resolution\n",
        "\n",
        "chaos_class = []\n",
        "\n",
        "experiment_length = 10000\n",
        "\n",
        "for experiment in range(experiment_length):\n",
        "  \n",
        "  if experiment % 1000 == 0:\n",
        "    print(\"Loading...\", experiment,\"/\",experiment_length)\n",
        "\n",
        "  # Randomly initialize a new RNN\n",
        "  width = 2\n",
        "  ACTIVATION = 'relu'\n",
        "  CLIPPING = 'noclip'\n",
        "\n",
        "  layer_in = Layer_Dense_In(1,width,'glorot','glorot')\n",
        "  layer_mid = Layer_Dense_Mid(width,width,'glorot','glorot')\n",
        "  layer_out = Layer_Dense_Out(width,1,'glorot','glorot',CLIPPING)\n",
        "\n",
        "  if ACTIVATION == 'relu':\n",
        "    layer_act1 = Activation_ReLU()\n",
        "    layer_act2 = Activation_ReLU()\n",
        "    layer_act3 = Activation_ReLU()\n",
        "  elif ACTIVATION == 'tanh':\n",
        "    layer_act1 = Activation_Tanh()\n",
        "    layer_act2 = Activation_Tanh()\n",
        "    layer_act3 = Activation_Tanh()\n",
        "\n",
        "  #layer_mid = Layer_Dense_Mid(width,width,'he','he')\n",
        "  #layer_act2 = Activation_Tanh()\n",
        "\n",
        "  #layer_act3 = Activation_Tanh()\n",
        "\n",
        "  # Set the granularity of the plot allocate memory\n",
        "  X_granularity = 163\n",
        "  window = 1\n",
        "  zero_line = np.linspace(0,0,num=X_granularity, endpoint=True)\n",
        "  test_X = np.linspace(-window,window,num=X_granularity, endpoint=True)\n",
        "  test_X_plot_F0 = np.linspace(-window,window,num=X_granularity, endpoint=True)\n",
        "  test_X_plot_F3 = np.linspace(-window,window,num=X_granularity, endpoint=True)\n",
        "\n",
        "  # Function calculation, f and f^3\n",
        "  for iter in range(len(test_X)):\n",
        "    test_X_plot_F0[iter] = RNN_Pass(test_X_plot_F0[iter])\n",
        "    test_X_plot_F3[iter] = RNN_Pass(RNN_Pass(RNN_Pass(test_X_plot_F0[iter])))\n",
        "\n",
        "  '''\n",
        "  plt.plot(test_X,test_X)\n",
        "  plt.plot(test_X,test_X_plot_F0)\n",
        "  plt.plot(test_X,test_X_plot_F3)\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  break\n",
        "  '''\n",
        "\n",
        "  f1_points = 0\n",
        "  f3_points = 0\n",
        "\n",
        "  for check in range(1,len(test_X)-1):\n",
        "    if (test_X[check-1]-test_X_plot_F0[check-1])*(test_X[check]-test_X_plot_F0[check]) < 0:\n",
        "      f1_points +=1\n",
        "    if (test_X[check-1]-test_X_plot_F3[check-1])*(test_X[check]-test_X_plot_F3[check]) < 0:\n",
        "      f3_points +=1\n",
        "    if (test_X[check]-test_X_plot_F3[check]) == 0:\n",
        "      if (test_X[check-1]-test_X_plot_F3[check-1])*(test_X[check+1]-test_X_plot_F3[check+1])<0:\n",
        "        f3_points +=1\n",
        "    if (test_X[check]-test_X_plot_F0[check]) == 0:\n",
        "      if (test_X[check-1]-test_X_plot_F0[check-1])*(test_X[check+1]-test_X_plot_F0[check+1])<0:\n",
        "        f1_points +=1\n",
        "\n",
        "  if f3_points - f1_points > 0:\n",
        "    if len(chaos_class)==0:\n",
        "      chaos_class.append(1)\n",
        "    else:\n",
        "      chaos_class.append(chaos_class[-1]+1)\n",
        "  else:\n",
        "    if len(chaos_class)==0:\n",
        "      chaos_class.append(0)\n",
        "    else:\n",
        "      chaos_class.append(chaos_class[-1])\n",
        "\n",
        "plt.plot(chaos_class)\n",
        "chaos_class_percentage = []\n",
        "\n",
        "for i in range(0,len(chaos_class)):\n",
        "  chaos_class_percentage.append((chaos_class[i])/(i+1))\n",
        "\n",
        "print(\"Chaos percentage = \", 100*chaos_class_percentage[-1],\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "exOlot7PKy6C",
        "outputId": "40200412-02d7-46b0-962a-a2398946084f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading... 0 / 10000\n",
            "Loading... 1000 / 10000\n",
            "Loading... 2000 / 10000\n",
            "Loading... 3000 / 10000\n",
            "Loading... 4000 / 10000\n",
            "Loading... 5000 / 10000\n",
            "Loading... 6000 / 10000\n",
            "Loading... 7000 / 10000\n",
            "Loading... 8000 / 10000\n",
            "Loading... 9000 / 10000\n",
            "Chaos percentage =  1.06 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6IqYL3FTSeA-"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}