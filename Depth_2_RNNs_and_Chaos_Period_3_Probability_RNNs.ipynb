{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Depth_2_RNNs_and_Chaos_Period_3_Probability_RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Characteristics of Network\n",
        "\n",
        "# Network Characteristics:\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "#|         Layer_1         |         Layer_2         ||    Chaos Percentage     |\n",
        "#|   w       b       Ïƒ()   |   w       b       Ïƒ()   ||                         |\n",
        "#|   1      He      ReLU   |   He     He        1    ||          ~13.77 %       |\n",
        "#|   He     He      ReLU   |   He     He      ReLU   ||           ~4.51 %       |\n",
        "#|   He      U      ReLU   |   He     U       ReLU   ||           ~7.49 %       |\n",
        "#|N(0,1/k) TR(-1,1) ReLU   |N(0,1/k) TR(-1,1) ReLU   ||           ~4.4 %        |\n",
        "#|Glorot   Glorot   ReLU   |Glorot   Glorot   ReLU   ||           ~2.28 %       |\n",
        "#|-------------------------|-------------------------||-------------------------|"
      ],
      "metadata": {
        "id": "zwCc33NjoJgy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3e7NrKrBd30H"
      },
      "outputs": [],
      "source": [
        "# Import Packages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import figure\n",
        "from scipy.interpolate import make_interp_spline\n",
        "from scipy.stats import truncnorm\n",
        "import scipy.stats as stats\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense Layer 1\n",
        "class Layer_Dense_In:\n",
        "\n",
        "  # Layer initialization\n",
        "  def __init__(self,n_inputs,n_neurons,w,b):\n",
        "    '''\n",
        "    Weight Initialization\n",
        "    '''\n",
        "    if w == 'he':\n",
        "      # He Initialization\n",
        "      self.weights = np.random.randn(n_inputs, n_neurons) * np.sqrt(2/n_inputs)\n",
        "    elif w == '1':\n",
        "      # 1 Initialization\n",
        "      self.weights = np.ones((n_inputs, n_neurons))\n",
        "    elif w == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.weights = 1 * np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.weights = (1/n_neurons)* np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'uniform':\n",
        "      # Uniform Initialization\n",
        "      self.weights = np.random.uniform(size=(n_inputs,n_neurons))\n",
        "    elif w == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.weights = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(n_inputs, n_neurons)\n",
        "    '''\n",
        "    Bias Initialization\n",
        "    '''\n",
        "    if b == 'he':\n",
        "      # He Initialization\n",
        "      self.biases = np.random.randn(1,n_neurons)* np.sqrt(2/n_inputs)\n",
        "    elif b == '1':\n",
        "      # 1 Initialization\n",
        "      self.biases = np.zeros((1, n_neurons))\n",
        "    elif b == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.biases = 1 * np.random.randn(1,n_neurons)\n",
        "    elif b == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.biases = (1/n_neurons)* np.random.randn(n_inputs, n_neurons)\n",
        "    elif b == 'uniform':\n",
        "      # Uniform Distribution\n",
        "      self.biases = np.random.uniform(size=(1,n_neurons))\n",
        "    elif b == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.biases = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(1, n_neurons)\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "# Dense Layer 2\n",
        "class Layer_Dense_Mid:\n",
        "\n",
        "  # Layer initialization\n",
        "  def __init__(self,n_inputs,n_neurons,w,b):\n",
        "    '''\n",
        "    Weight Initialization\n",
        "    '''\n",
        "    if w == 'he':\n",
        "      # He Initialization\n",
        "      self.weights = np.random.randn(n_inputs, n_neurons) * np.sqrt(2/n_inputs)\n",
        "    elif w == '1':\n",
        "      # 1 Initialization\n",
        "      self.weights = np.ones((n_inputs, n_neurons))\n",
        "    elif w == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.weights = 1 * np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.weights = (1/n_neurons)* np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'uniform':\n",
        "      # Uniform Initialization\n",
        "      self.weights = np.random.uniform(size=(n_inputs,n_neurons))\n",
        "    elif w == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.weights = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(n_inputs, n_neurons)\n",
        "    '''\n",
        "    Bias Initialization\n",
        "    '''\n",
        "    if b == 'he':\n",
        "      # He Initialization\n",
        "      self.biases = np.random.randn(1,n_neurons)* np.sqrt(2/n_inputs)\n",
        "    elif b == '1':\n",
        "      # 1 Initialization\n",
        "      self.biases = np.zeros((1, n_neurons))\n",
        "    elif b == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.biases = 1 * np.random.randn(1,n_neurons)\n",
        "    elif b == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.biases = (1/n_neurons)* np.random.randn(1, n_neurons)\n",
        "    elif b == 'uniform':\n",
        "      # Uniform Distribution\n",
        "      self.biases = np.random.uniform(size=(1,n_neurons))\n",
        "    elif b == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.biases = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(1, n_neurons)\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "# Dense Layer 3\n",
        "class Layer_Dense_Out:\n",
        "  \n",
        "    # Layer initialization\n",
        "  def __init__(self,n_inputs,n_neurons,w,b,clip):\n",
        "\n",
        "    if clip == 'clip':\n",
        "      self.clipping_flag = True\n",
        "    else:\n",
        "      self.clipping_flag = False\n",
        "    '''\n",
        "    Weight Initialization\n",
        "    '''\n",
        "    if w == 'he':\n",
        "      # He Initialization\n",
        "      self.weights = np.random.randn(n_inputs, n_neurons) * np.sqrt(2/n_inputs)\n",
        "    elif w == '1':\n",
        "      # 1 Initialization\n",
        "      self.weights = np.ones((n_inputs, n_neurons))\n",
        "    elif w == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.weights = 1 * np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.weights = (1/n_neurons)* np.random.randn(n_inputs, n_neurons)\n",
        "    elif w == 'uniform':\n",
        "      # Uniform Initialization\n",
        "      self.weights = np.random.uniform(size=(n_inputs,n_neurons))\n",
        "    elif w == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.weights = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(n_inputs, n_neurons)\n",
        "    '''\n",
        "    Bias Initialization\n",
        "    '''\n",
        "    if b == 'he':\n",
        "      # He Initialization\n",
        "      self.biases = np.random.randn(1,n_neurons)* np.sqrt(2/n_inputs)\n",
        "    elif b == '1':\n",
        "      # 1 Initialization\n",
        "      self.biases = np.zeros((1, n_neurons))\n",
        "    elif b == 'normal':\n",
        "      # Normal Initialization    \n",
        "      self.biases = 1 * np.random.randn(1,n_neurons)\n",
        "    elif b == 'normal_k':\n",
        "      # Normal Initialization    \n",
        "      self.biases = (1/n_neurons)* np.random.randn(1, n_neurons)\n",
        "    elif b == 'uniform':\n",
        "      # Uniform Distribution\n",
        "      self.biases = np.random.uniform(size=(1,n_neurons))\n",
        "    elif b == 'glorot':\n",
        "      # Glorot Initialization\n",
        "      self.biases = np.sqrt(2.0/(n_inputs +n_neurons)) * np.random.randn(1, n_neurons)\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Output clipping [0,1]\n",
        "    if self.clipping_flag == True:\n",
        "      if self.output > 1:\n",
        "        self.output = 1\n",
        "      if self.output < 0:\n",
        "        self.output = 0"
      ],
      "metadata": {
        "id": "JPuv3ulaePI1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#|------------------------------------------------------------------------------|\n",
        "#|                                                                              |\n",
        "#|                                ORIGINAL TABLE                                |\n",
        "#|                                                                              |\n",
        "#|CLIPPING|ACTIVATION|WIDTH|DEPTH|                                              |\n",
        "#|  NO   |   RELU   |  2  |  2  |                                               |\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "#|         Layer_1         |         Layer_2         ||    Chaos Percentage     |\n",
        "#|   w       b       Ïƒ()   |   w       b       Ïƒ()   ||                         |\n",
        "#|   1      He      ReLU   |   He     He        1    ||          ~13.77%        |\n",
        "#|   He     He      ReLU   |   He     He      ReLU   ||          ~7.49%         |\n",
        "#|   He      U      ReLU   |   He     U       ReLU   ||          ~4.51%         |\n",
        "#|N(0,1/k) TR(-1,1) ReLU   |N(0,1/k) TR(-1,1) ReLU   ||          ~4.45%         |\n",
        "#|Glorot   Glorot   ReLU   |Glorot   Glorot   ReLU   ||          ~2.28%         |\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "\n",
        "\n",
        "#|------------------------------------------------------------------------------|\n",
        "#|                                                                              |\n",
        "#|                                EXTRA TABLE 1                                 |\n",
        "#|                                                                              |\n",
        "#|CLIPPING|ACTIVATION|WIDTH|DEPTH|                                              |\n",
        "#|  YES   |   RELU   |  2  |  2  |                                              |\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "#|         Layer_1         |         Layer_2         ||    Chaos Percentage     |\n",
        "#|   w       b       Ïƒ()   |   w       b       Ïƒ()   ||                         |\n",
        "#|   1      He      ReLU   |   He     He        1    ||          ~4.7%          |\n",
        "#|   He     He      ReLU   |   He     He      ReLU   ||          ~5.4%          |\n",
        "#|   He      U      ReLU   |   He     U       ReLU   ||          ~1.6%          |\n",
        "#|N(0,1/k) TR(-1,1) ReLU   |N(0,1/k) TR(-1,1) ReLU   ||          ~3.9%          |\n",
        "#|Glorot   Glorot   ReLU   |Glorot   Glorot   ReLU   ||          ~2.3%          |\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "\n",
        "#|------------------------------------------------------------------------------|\n",
        "#|                                                                              |\n",
        "#|                                EXTRA TABLE 2                                 |\n",
        "#|                                                                              |\n",
        "#|CLIPPING|ACTIVATION|WIDTH|DEPTH|                                              |\n",
        "#|  YES   |   TANH   |  2  |  2  |                                              |\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "#|         Layer_1         |         Layer_2         ||    Chaos Percentage     |\n",
        "#|   w       b       Ïƒ()   |   w       b       Ïƒ()   ||                         |\n",
        "#|   1      He      ReLU   |   He     He        1    ||          ~6.6%          |\n",
        "#|   He     He      ReLU   |   He     He      ReLU   ||          ~6.2%          |\n",
        "#|   He      U      ReLU   |   He     U       ReLU   ||          ~9.8%          |\n",
        "#|N(0,1/k) TR(-1,1) ReLU   |N(0,1/k) TR(-1,1) ReLU   ||          ~4.8%          |\n",
        "#|Glorot   Glorot   ReLU   |Glorot   Glorot   ReLU   ||          ~2.8%          |\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "\n",
        "\n",
        "\n",
        "# WIDTH = 4 (without clipping, tanh activation)\n",
        "\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "#|         Layer_1         |         Layer_2         ||    Chaos Percentage     |\n",
        "#|   w       b       Ïƒ()   |   w       b       Ïƒ()   ||                         |\n",
        "#|   1      He      ReLU   |   He     He        1    ||          ~7.8%          |\n",
        "#|   He     He      ReLU   |   He     He      ReLU   ||          ~8.3%          |\n",
        "#|   He      U      ReLU   |   He     U       ReLU   ||          ~7.2%          |\n",
        "#|N(0,1/k) TR(-1,1) ReLU   |N(0,1/k) TR(-1,1) ReLU   ||          ~10.6%         | \n",
        "#|Glorot   Glorot   ReLU   |Glorot   Glorot   ReLU   ||          ~4.0%          |\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "\n",
        "# WIDTH = 64 (without clipping, tanh activation)\n",
        "\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "#|         Layer_1         |         Layer_2         ||    Chaos Percentage     |\n",
        "#|   w       b       Ïƒ()   |   w       b       Ïƒ()   ||                         |\n",
        "#|   1      He      ReLU   |   He     He        1    ||          ~15.8%         |\n",
        "#|   He     He      ReLU   |   He     He      ReLU   ||          ~14.8%         |\n",
        "#|   He      U      ReLU   |   He     U       ReLU   ||          ~12.4%         |\n",
        "#|N(0,1/k) TR(-1,1) ReLU   |N(0,1/k) TR(-1,1) ReLU   ||          ~21.9%         | \n",
        "#|Glorot   Glorot   ReLU   |Glorot   Glorot   ReLU   ||          ~10.9%         |\n",
        "#|-------------------------|-------------------------||-------------------------|\n",
        "\n",
        "# DEPTH = 3 (without clipping, ReLU activation, width = 2)\n",
        "\n",
        "#|-------------------------|-------------------------||------------------------||                         |\n",
        "#|         Layer_1         |         Layer_2         |         Layer_3         ||    Chaos Percentage     |\n",
        "#|   w       b       Ïƒ()   |   w       b       Ïƒ()   |   w       b       Ïƒ()   ||                         |\n",
        "#|   1      He      ReLU   |   He     He      ReLU   |   He      He      1     ||          ~0.8%          |\n",
        "#|   He     He      ReLU   |   He     He      ReLU   |   He     He      ReLU   ||          ~0.7%          |\n",
        "#|   He      U      ReLU   |   He     U       ReLU   |   He     U       ReLU   ||          ~0.2%          |\n",
        "#|N(0,1/k) TR(-1,1) ReLU   |N(0,1/k) TR(-1,1) ReLU   |N(0,1/k) TR(-1,1) ReLU   ||          ~2.3%          | \n",
        "#|Glorot   Glorot   ReLU   |Glorot   Glorot   ReLU   |Glorot   Glorot   ReLU   ||          ~2.6%          |\n",
        "#|-------------------------|-------------------------|-------------------------||                         |"
      ],
      "metadata": {
        "id": "qCliEkuhXtFg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ReLU activation\n",
        "class Activation_ReLU:\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    # Calculate output values from inputs\n",
        "    self.output = np.maximum(0,inputs)\n",
        "\n",
        "# Tanh activation\n",
        "class Activation_Tanh:\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self,inputs):\n",
        "    # Calculate output values from inputs\n",
        "    self.output = np.tanh(inputs)\n",
        "\n",
        "# Data Flow at every composition\n",
        "def RNN_Pass(input):\n",
        "\n",
        "  layer_in.forward(input)\n",
        "  layer_act1.forward(layer_in.output)\n",
        "  #layer_mid.forward(layer_act1.output)\n",
        "  #layer_act2.forward(layer_mid.output)\n",
        "  layer_out.forward(layer_act1.output)\n",
        "  layer_act3.forward(layer_out.output)\n",
        "\n",
        "  return layer_act3.output"
      ],
      "metadata": {
        "id": "DdckGOkehIr1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Loop - Mapping of [0,1] -> [0,1]\n",
        "\n",
        "# Initialization parameters:\n",
        "# * Network Depth\n",
        "# * Image Resolution\n",
        "\n",
        "chaos_class = []\n",
        "\n",
        "experiment_length = 10000\n",
        "\n",
        "for experiment in range(experiment_length):\n",
        "  \n",
        "  if experiment % 1000 == 0:\n",
        "    print(\"Loading...\", experiment,\"/\",experiment_length)\n",
        "\n",
        "  # Randomly initialize a new RNN\n",
        "  width = 4\n",
        "  ACTIVATION = 'relu'\n",
        "  CLIPPING = 'noclip'\n",
        "\n",
        "  layer_in = Layer_Dense_In(1,width,'he','he')\n",
        "  layer_out = Layer_Dense_Out(width,1,'he','he',CLIPPING)\n",
        "\n",
        "  if ACTIVATION == 'relu':\n",
        "    layer_act1 = Activation_ReLU()\n",
        "    layer_act3 = Activation_ReLU()\n",
        "  elif ACTIVATION == 'tanh':\n",
        "    layer_act1 = Activation_Tanh()\n",
        "    layer_act3 = Activation_Tanh()\n",
        "\n",
        "  #layer_mid = Layer_Dense_Mid(width,width,'he','he')\n",
        "  #layer_act2 = Activation_Tanh()\n",
        "\n",
        "  #layer_act3 = Activation_Tanh()\n",
        "\n",
        "  # Set the granularity of the plot allocate memory\n",
        "  X_granularity = 163\n",
        "  window = 1\n",
        "  zero_line = np.linspace(0,0,num=X_granularity, endpoint=True)\n",
        "  test_X = np.linspace(-window,window,num=X_granularity, endpoint=True)\n",
        "  test_X_plot_F0 = np.linspace(-window,window,num=X_granularity, endpoint=True)\n",
        "  test_X_plot_F3 = np.linspace(-window,window,num=X_granularity, endpoint=True)\n",
        "\n",
        "  # Function calculation, f and f^3\n",
        "  for iter in range(len(test_X)):\n",
        "    test_X_plot_F0[iter] = RNN_Pass(test_X_plot_F0[iter])\n",
        "    test_X_plot_F3[iter] = RNN_Pass(RNN_Pass(RNN_Pass(test_X_plot_F0[iter])))\n",
        "\n",
        "  '''\n",
        "  plt.plot(test_X,test_X)\n",
        "  plt.plot(test_X,test_X_plot_F0)\n",
        "  plt.plot(test_X,test_X_plot_F3)\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  break\n",
        "  '''\n",
        "\n",
        "  f1_points = 0\n",
        "  f3_points = 0\n",
        "\n",
        "  for check in range(1,len(test_X)-1):\n",
        "    if (test_X[check-1]-test_X_plot_F0[check-1])*(test_X[check]-test_X_plot_F0[check]) < 0:\n",
        "      f1_points +=1\n",
        "    if (test_X[check-1]-test_X_plot_F3[check-1])*(test_X[check]-test_X_plot_F3[check]) < 0:\n",
        "      f3_points +=1\n",
        "    if (test_X[check]-test_X_plot_F3[check]) == 0:\n",
        "      if (test_X[check-1]-test_X_plot_F3[check-1])*(test_X[check+1]-test_X_plot_F3[check+1])<0:\n",
        "        f3_points +=1\n",
        "    if (test_X[check]-test_X_plot_F0[check]) == 0:\n",
        "      if (test_X[check-1]-test_X_plot_F0[check-1])*(test_X[check+1]-test_X_plot_F0[check+1])<0:\n",
        "        f1_points +=1\n",
        "\n",
        "  if f3_points - f1_points > 0:\n",
        "    if len(chaos_class)==0:\n",
        "      chaos_class.append(1)\n",
        "    else:\n",
        "      chaos_class.append(chaos_class[-1]+1)\n",
        "  else:\n",
        "    if len(chaos_class)==0:\n",
        "      chaos_class.append(0)\n",
        "    else:\n",
        "      chaos_class.append(chaos_class[-1])\n",
        "\n",
        "plt.plot(chaos_class)\n",
        "chaos_class_percentage = []\n",
        "\n",
        "for i in range(0,len(chaos_class)):\n",
        "  chaos_class_percentage.append((chaos_class[i])/(i+1))\n",
        "\n",
        "print(\"Chaos percentage = \", 100*chaos_class_percentage[-1],\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "exOlot7PKy6C",
        "outputId": "194b5464-ef44-4a80-d21a-1eafea368a7e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading... 0 / 10000\n",
            "Loading... 1000 / 10000\n",
            "Loading... 2000 / 10000\n",
            "Loading... 3000 / 10000\n",
            "Loading... 4000 / 10000\n",
            "Loading... 5000 / 10000\n",
            "Loading... 6000 / 10000\n",
            "Loading... 7000 / 10000\n",
            "Loading... 8000 / 10000\n",
            "Loading... 9000 / 10000\n",
            "Chaos percentage =  8.77 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-SpD_vpS8Nk-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
